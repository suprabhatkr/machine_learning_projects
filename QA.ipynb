{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['the cow is a domestic animal which is considered useful to mankind.', 'it is used as livestock mainly for providing various dairy products like milk, ghee and cheese.', 'it is found in various colours, shapes and sizes around the world.', 'in india, the cow is regarded as a sacred animal and worshipped by hindus from ancient times.', 'it has two ears and eyes each, one big nose, two sharp horns, a long tail and four limbs.', 'it eats fresh grass, husk, grain and vegetables.', 'cowâ€™s milk is very nutritious and beneficial for human consumption.', 'drinking cow milk regularly sharpens our brain and increases immunity power.', 'farmers often use a male cow known as an ox to plough the fields and draw carts.', 'the cow dung is used by people as fuel and fertilizer for plants and for repelling insects']\n"
     ]
    }
   ],
   "source": [
    "from nltk.tokenize import sent_tokenize,word_tokenize\n",
    "import re\n",
    "with open('cowEssay.txt', 'r') as file:\n",
    "    text = file.read()\n",
    "text=text.lower()\n",
    "sentences=sent_tokenize(text)\n",
    "print(sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "reflections = {\n",
    "  \"i am\"       : \"you are\",\n",
    "  \"i was\"      : \"you were\",\n",
    "  \"i\"          : \"you\",\n",
    "  \"i'm\"        : \"you are\",\n",
    "  \"i'd\"        : \"you would\",\n",
    "  \"i've\"       : \"you have\",\n",
    "  \"i'll\"       : \"you will\",\n",
    "  \"my\"         : \"your\",\n",
    "  \"you are\"    : \"I am\",\n",
    "  \"you were\"   : \"I was\",\n",
    "  \"you've\"     : \"I have\",\n",
    "  \"you'll\"     : \"I will\",\n",
    "  \"your\"       : \"my\",\n",
    "  \"yours\"      : \"mine\",\n",
    "  \"you\"        : \"me\",\n",
    "  \"me\"         : \"you\"\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "pairs = [\n",
    "    [\n",
    "        r\"my name is (.*)\",\n",
    "        [\"Hello %1, How are you today ?\",]\n",
    "    ],\n",
    "     [\n",
    "        r\"what is your name ?\",\n",
    "        [\"My name is Chatty and I'm a chatbot ?\",]\n",
    "    ],\n",
    "    [\n",
    "        r\"how are you ?\",\n",
    "        [\"I'm doing good\\nHow about You ?\",]\n",
    "    ],\n",
    "    [\n",
    "        r\"sorry (.*)\",\n",
    "        [\"Its alright\",\"Its OK, never mind\",]\n",
    "    ],\n",
    "    [\n",
    "        r\"i'm (.*) doing good\",\n",
    "        [\"Nice to hear that\",\"Alright :)\",]\n",
    "    ],\n",
    "    [\n",
    "        r\"hi|hey|hello\",\n",
    "        [\"Hello\", \"Hey there\",]\n",
    "    ],\n",
    "    [\n",
    "        r\"(.*) age?\",\n",
    "        [\"I'm a computer program dude\\nSeriously you are asking me this?\",]\n",
    "        \n",
    "    ],\n",
    "    [\n",
    "        r\"what (.*) want ?\",\n",
    "        [\"Make me an offer I can't refuse\",]\n",
    "        \n",
    "    ],\n",
    "    [\n",
    "        r\"(.*) (location|city) ?\",\n",
    "        ['Patna, Bihar',]\n",
    "    ],\n",
    "    [\n",
    "        r\"how is weather in (.*)?\",\n",
    "        [\"Weather in %1 is awesome like always\",\"Too hot man here in %1\",\"Too cold man here in %1\",\"Never even heard about %1\"]\n",
    "    ],\n",
    "    [\n",
    "        r\"i work in (.*)?\",\n",
    "        [\"%1 is an Amazing company, I have heard about it. But they are in huge loss these days.\",]\n",
    "    ],\n",
    "[\n",
    "        r\"(.*)raining in (.*)\",\n",
    "        [\"No rain since last week here in %2\",\"Damn its raining too much here in %2\"]\n",
    "    ],\n",
    "    [\n",
    "        r\"how (.*) health(.*)\",\n",
    "        [\"So I'm always healthy \",]\n",
    "    ],\n",
    "    [\n",
    "        r\"(.*) (sports|game) ?\",\n",
    "        [\"I'm a very big fan of Football\",]\n",
    "    ],\n",
    "    [\n",
    "        r\"who (.*) sportsperson ?\",\n",
    "        [\"Virat\",\"Dhoni\",\"Sachin\"]\n",
    "],\n",
    "    [\n",
    "        r\"who (.*) (moviestar|actor)\",\n",
    "        [\"Brad Pitt\",\"Christian Bale\",\"Leonardo Dicaprio\",\"\"]\n",
    "],\n",
    "    [\n",
    "        r\"quit\",\n",
    "        [\"Bye take care. See you soon :) \",\"It was nice talking to you. See you soon :)\"]\n",
    "],\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['the cow is a domestic animal which is considered useful to mankind .', 'the cow  is used as livestock mainly for providing various dairy products like milk , ghee and cheese .', 'the cow  is found in various colours , shapes and sizes around the world .', 'in india , the cow is regarded as a sacred animal and worshipped by hindus from ancient times .', 'in india , the cow  has two ears and eyes each , one big nose , two sharp horns , a long tail and four limbs .', 'in india , the cow  eats fresh grass , husk , grain and vegetables .', 'cowâ€™s milk is very nutritious and beneficial for human consumption .', 'drinking cow milk regularly sharpens our brain and increases immunity power .', 'farmers often use a male cow known as an ox to plough the fields and draw carts .', 'the cow dung is used by people as fuel and fertilizer for plants and for repelling insects']\n"
     ]
    }
   ],
   "source": [
    "sentVector=[]\n",
    "subject=None\n",
    "for sentence in sentences:\n",
    "    sentVector.append(word_tokenize(sentence))\n",
    "    if re.search(\"(the|a|an)? (.*) (is|are|will|shall|was|were) (.*)\",sentence)!=None:\n",
    "        subject=''\n",
    "        for i in range(len(sentVector[-1])):\n",
    "            if re.search('(is|are|will|shall|was|were)',sentVector[-1][i])==None:\n",
    "                subject+=sentVector[-1][i] \n",
    "                subject+=\" \"\n",
    "            else:\n",
    "                break\n",
    "    else:\n",
    "        if re.search(\"(it|this|he|she|they)\",sentVector[-1][0])!=None:\n",
    "            sentVector[-1][0]=subject\n",
    "sentences=\"\"\n",
    "for sentence in sentVector:\n",
    "    for word in sentence:\n",
    "        sentences+=word\n",
    "        sentences+=\" \"\n",
    "sentences=sent_tokenize(sentences)\n",
    "print(sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import wikipedia\n",
    "from nltk.corpus import stopwords\n",
    "stop_words = list(stopwords.words('english'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For stop write \"quit\"\n",
      "what is a cow?\n",
      "the cow is a domestic animal which is considered useful to mankind .\n",
      "how is cows milk?\n",
      "the cow  is used as livestock mainly for providing various dairy products like milk , ghee and cheese .\n",
      "where is cow regarded as sacred animal?\n",
      "in india , the cow is regarded as a sacred animal and worshipped by hindus from ancient times .\n",
      "quit\n",
      "Bye take care. See you soon :) \n"
     ]
    }
   ],
   "source": [
    "inp=None\n",
    "print('For stop write \"quit\"')\n",
    "while(inp!=\"quit\"):\n",
    "    inp=input()\n",
    "    inp=inp.lower()\n",
    "    ans=None\n",
    "    for p in pairs:\n",
    "        if re.search(p[0],inp)!=None:\n",
    "            ans=\"\"\n",
    "            wordList=list(inp.split(' '))\n",
    "            for i in range(len(wordList)):\n",
    "                if wordList[i] in reflections.keys():\n",
    "                    ans+=reflections[wordList[i]]\n",
    "                    if(i<len(wordList)):\n",
    "                        ans+=(\" \"+wordList[i+1])\n",
    "                    ans+=(\" \"+wordList[i-1]+\" \")\n",
    "            ans+=p[1][0]\n",
    "    nonStop=[]\n",
    "    inpVector=word_tokenize(inp)\n",
    "    for word in inpVector:\n",
    "        if word not in stop_words:\n",
    "            nonStop.append(word)\n",
    "    inpWords=[]\n",
    "#     if re.search(\"(what|who|which) is.*\",inp)!=None:\n",
    "#         l=inp.split(\" \")\n",
    "#         for word in l:\n",
    "#             if word not in stop_words:\n",
    "#                 inpWords.append(word)\n",
    "    if len(nonStop)!=0:\n",
    "        for s in sentences:\n",
    "            for w in nonStop:\n",
    "                x=re.search(\"(a|an|the)? \"+w+\" (is|are|was|were).*\",s)\n",
    "            if x!=None:\n",
    "                subject=w\n",
    "                ans=s \n",
    "                break\n",
    "        maxCount=0\n",
    "        if ans!=None:\n",
    "            for w in nonStop:\n",
    "                if w in ans:\n",
    "                    maxCount+=1\n",
    "        for s in sentences:\n",
    "            count=0\n",
    "            for w in nonStop:\n",
    "                if w in s:\n",
    "                    count+=1\n",
    "            if count>maxCount:\n",
    "                maxCount=count\n",
    "                ans=s\n",
    "    if ans==None:\n",
    "        try:\n",
    "            ans=wikipedia.summary(nonStop[0],sentences=1)\n",
    "        except:\n",
    "            ans=\"Sorry I can't help.\"\n",
    "    print(ans) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "file_extension": ".py",
  "kernelspec": {
   "display_name": "Python 3.7.6 64-bit",
   "language": "python",
   "name": "python37664bit64a37ecbee8847aeb2b23c19bc2435b5"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  },
  "mimetype": "text/x-python",
  "name": "python",
  "npconvert_exporter": "python",
  "pygments_lexer": "ipython3",
  "version": 3
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
